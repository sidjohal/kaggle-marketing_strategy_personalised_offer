{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Essentials","metadata":{}},{"cell_type":"code","source":"import time, datetime\nstart = time.time()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_train = pd.read_csv(\"/kaggle/input/marketing-strategy-personalised-offer/train_data.csv\")\nraw_test = pd.read_csv(\"/kaggle/input/marketing-strategy-personalised-offer/test_data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data statistics","metadata":{}},{"cell_type":"code","source":"raw_train.shape, raw_test.shape, raw_train.dtypes.sort_values().value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_train.isna().sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = raw_train.copy()\ntest = raw_test.copy()\n\nlabels = features[\"Offer Accepted\"].copy()\nfeatures.drop('Offer Accepted', axis=1, inplace=True)\n\nfeatures.drop('car', axis=1, inplace=True)\ntest.drop('car', axis=1, inplace=True)\n\n#features.dtypes.sort_values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Problem is of binary classification type - (Yes / No)**","metadata":{}},{"cell_type":"code","source":"#features.isna().sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Features and labels have been split\n* Features have categorical and numerical values\n* Missing values are only in the categorical features\n    * Since feature 'car' has the missing values comparable to data, thus can be dropped","metadata":{}},{"cell_type":"markdown","source":"### Phase 1\n# Data preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Data wrangling**\n* Feature imputation\n* Categorical and numerical transformers\n* Feature scaling","metadata":{}},{"cell_type":"code","source":"#before = x.shape\n\n# shorthand code - drop columns that only contain one value\nfeatures.drop([i for i in features.columns if len(features[i].unique())==1], axis=1, inplace=True)\n\n# repeat for test data\ntest.drop([i for i in test.columns if len(test[i].unique())==1], axis=1, inplace=True)\n\n#after = x.shape\n#before, after","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list numerical and categorical features\n\nnumerical, categorical = [], []\n\nfor i in features.columns:\n    n = features[i].dtype\n    if (n=='int64'):\n        numerical.append(i)\n    elif (n=='O'):\n        categorical.append(i)\n        \nlen(categorical)+len(numerical)==len(features.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature imputation","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"si = SimpleImputer(strategy=\"most_frequent\")\n\n# separate dataframes for categorical and numerical features\nnumdf_tr = features[numerical]\ncatdf_tr = features[categorical]\n\n# impute missing values in categorical features and concatnate with numerical\ncatdf_tr = pd.DataFrame(si.fit_transform(catdf_tr), columns=catdf_tr.columns)\nfeatures = pd.concat([catdf_tr, numdf_tr], axis=1)\n\n# repeat for test data\n# seaprate\nnumdf_te = test[numerical]\ncatdf_te = test[categorical]\n# impute\ncatdf_te = pd.DataFrame(si.fit_transform(catdf_te), columns=catdf_tr.columns) # putting catdf_tr columns as a check\ntest = pd.concat([catdf_te, numdf_te], axis=1)\n\nfeatures.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Features imputation done, now we can apply encoders**\n\n**Categorical features should be divided into ordinal and nominal and encoders should be applied accordingly**","metadata":{}},{"cell_type":"code","source":"unique = {}\nfor i in sorted(categorical):\n    unique[i] = features[i].unique()\n    \nunique = pd.DataFrame(unique.items(), columns=['features', 'unique values'])\nunique","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['age'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can group values in ['age'] into bins of below21, 21-50 and 50plus**","metadata":{}},{"cell_type":"code","source":"# create a series copy of age column\nage_tr = features['age'].copy()\n\n# iterate through to find values between 21 and 50\n# since age is in string format, we search by eliminating\n\nfor i in range(len(age_tr)):\n    n = age_tr.loc[i]\n    if (n=='50plus' or n=='below21'):\n        pass\n    else:\n        age_tr = age_tr.replace(n, '21to50')\n\n# drop original age column and add transformed age searies column\nfeatures.drop('age', axis=1, inplace=True)\nfeatures['age'] = age_tr\nfeatures['age'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# repeat for test data\n\nage_te = test['age'].copy()\n\nfor i in range(len(age_te)):\n    n = age_te.loc[i]\n    if (n=='50plus' or n=='below21'):\n        pass\n    else:\n        age_te = age_te.replace(n, '21to50')\n\ntest.drop('age', axis=1, inplace=True)\ntest['age'] = age_te\ntest['age'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking unique values to separate ordinal and nominal features\n\n#unique","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From above, we separate ordinal features for OrdinalEncoder and nominal features for OneHotEncoder**\n\n    Indices for \n        Ordinal = 4, 5, 6, 7, 10, 11, 12, 13, 14","metadata":{}},{"cell_type":"code","source":"ordinal = [(sorted(categorical))[i] for i in [4, 5, 6, 7, 10, 11, 12, 13, 14]]\nnominal = [i for i in categorical if i not in ordinal]\n\nprint(len(ordinal), len(nominal), \"\\n\", ordinal)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor i in nominal:\n    count += len(features[i].unique())\n\nprint(\"unique values in nominal features =\", count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**47 unique columns from nominal features and 9 from ordinal features should finally give us 56 columns for categorical features**","metadata":{}},{"cell_type":"code","source":"unique = {}\nfor i in ordinal:\n    unique[i] = features[i].unique()\npd.DataFrame(unique.items(), columns=['features', 'unique values'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Specifying categories for ordinal features for OrdinalEncoding**","metadata":{}},{"cell_type":"code","source":"category = {\n    'income_range': ['Less than ₹12500', '₹12500 - ₹24999', '₹25000 - ₹37499', '₹37500 - ₹49999', '₹50000 - ₹62499', '₹62500 - ₹74999', '₹75000 - ₹87499', '₹87500 - ₹99999', '₹100000 or More'],\n    'Restaur_spend_greater_than20': ['never', 'less1', '1~3', '4~8', 'gt8'],\n    'no_visited_Cold drinks': ['never', 'less1', '1~3', '4~8', 'gt8'],\n    'Restaur_spend_less_than20': ['never', 'less1', '1~3', '4~8', 'gt8'], \n    'age': ['below21', '21to50', '50plus'],\n    'no_visited_bars': ['never', 'less1', '1~3', '4~8', 'gt8'],\n    'no_Take-aways' : ['never', 'less1', '1~3', '4~8', 'gt8'],\n    'Qualification' : ['Some High School', 'High School Graduate', 'Associates degree', 'Some college - no degree', 'Bachelors degree', 'Graduate degree (Masters or Doctorate)'],\n    'offer expiration': ['2days', '10hours']\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ColumnTransformer","metadata":{"execution":{"iopub.status.busy":"2022-11-29T05:43:52.020110Z","iopub.execute_input":"2022-11-29T05:43:52.020461Z","iopub.status.idle":"2022-11-29T05:43:52.074455Z","shell.execute_reply.started":"2022-11-29T05:43:52.020437Z","shell.execute_reply":"2022-11-29T05:43:52.073335Z"}}},{"cell_type":"markdown","source":"**Combining categorical encoders and numerical scalers in ColumnTransformer**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.compose import ColumnTransformer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking if total columns match before we add new ones\nlen(features.columns) == len(ordinal) + len(nominal) + len(numerical)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature = list(category.keys())\ncols = list(category.values())\n\nct = ColumnTransformer([\n    (\"ordenc\", OrdinalEncoder(categories=[i for i in cols]), [j for j in feature]),\n    (\"onehotenc\", OneHotEncoder(), [j for j in nominal]),\n    (\"minmax\", MinMaxScaler(), [j for j in numerical])\n], sparse_threshold=0)\n\n# instead of sparse_threshold, alt we can use sparse=False in OneHotEncoder\n\nfeatures = pd.DataFrame(ct.fit_transform(features))\nfeatures.columns = [str(i) for i in range(1, features.shape[1]+1)]\n\ntest = pd.DataFrame(ct.fit_transform(test))\ntest.columns = [str(i) for i in range(1, test.shape[1]+1)]\nfeatures.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.Series(LabelEncoder().fit_transform(labels))\nlabels.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\n    Loaded data\n    Separated features and labels\n    Dropped columns like empty, single valued, etc.\n    Imputed missing values (only in categorical in this data)\n    Listed ordinal, nominal and numerical features\n    Applied OrdinalEncoder and OneHotEncoder for ordinal and nominal features respectively\n    Scaled Numerical features using MinMaxScaler (alt. StandardScaler)\n    Encoded labels using LabelEncoder\n    Simultaneously pre-processed train and test data to avoid errors","metadata":{}},{"cell_type":"markdown","source":"### Phase 2\n# Dimensionality reduction","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectPercentile, GenericUnivariateSelect, mutual_info_regression, chi2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.var().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=3)\n\npca_features = pca.fit_transform(features)\npca_test = pca.fit_transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Phase 3\n\n# Model selection","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx, X_test, y, y_test = train_test_split(features ,labels , test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(x ,y , test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(model):\n    print(\"val:\",round(f1_score(y_val, model.predict(X_val)),4), \"\\ntest:\", round(f1_score(y_test, model.predict(X_test)),4))\n\ndef make_submission(clf, path):\n    pred = pd.DataFrame(clf.predict(test)).replace({1:\"Yes\", 0:\"No\"})\n\n    submission = pd.concat([pd.DataFrame(list(range(len(pred)))), pred], axis=1)\n    submission.columns = ['id', 'Offer Accepted']\n\n    submission.to_csv(path+\"submissions/submission.csv\", index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline Model","metadata":{}},{"cell_type":"code","source":"from sklearn.dummy import DummyClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = DummyClassifier()\nclf.fit(X_train, y_train)\n\nget_score(clf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(clf.predict(X_test)).unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SGD Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = SGDClassifier()\nclf.fit(X_train, y_train)\n\nget_score(clf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"penalties = ['elasticnet', 'l1', 'l2', 'none']\n\nfor i in penalties:\n    if (i=='elasticnet'):\n        log_reg = LogisticRegression(solver='saga', penalty=i, l1_ratio=0.5)\n    else:\n        log_reg = LogisticRegression(solver='saga', penalty=i)\n    \n    log_reg.fit(X_train, y_train)\n    print(i, get_score(log_reg), \"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"n_neighbors\":list(range(1,20))\n}\n\ngrid = GridSearchCV(KNeighborsClassifier(), param_grid=params, scoring=\"f1\", n_jobs=-1, cv=3).fit(X_train, y_train)\ngrid.best_score_, grid.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = grid.best_estimator_\n\nclf.fit(X_train, y_train)\n\nget_score(clf) # custom get_score function created above","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {'C':[0.1,1,10],'gamma':[0.1, 1, 10], 'degree':[2,3]}\ngrid = GridSearchCV(SVC(kernel='poly'),param_grid,refit = True)\ngrid.fit(X_train,y_train)\n\nclf = grid.best_estimator_\nclf.fit(X_train, y_train)\nget_score(clf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {'C':[0.1,1,10],'gamma':[0.1, 1, 10]}\ngrid = GridSearchCV(SVC(kernel='rbf'),param_grid,refit = True)\ngrid.fit(X_train,y_train)\n\nclf = grid.best_estimator_\nclf.fit(X_train, y_train)\nget_score(clf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CART","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"max_depth\": list(range(1,10)),\n    \"min_samples_split\": [2,5,7,10],\n    \"min_samples_leaf\": [1,2,5]\n}\n\ngrid = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid=params, scoring=\"f1\", n_jobs=-1, cv=3).fit(X_train, y_train)\ngrid.best_score_, grid.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = grid.best_estimator_\n\nclf.fit(X_train, y_train)\n\nget_score(clf) # custom get_score function created above","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Boosting","metadata":{}},{"cell_type":"code","source":"cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### AdaBoost","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ada = AdaBoostClassifier()\n\nada.fit(X_train, y_train)\n\nget_score(ada), sorted(cross_val_score(ada, X_train, y_train, cv=cv, scoring='f1'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GradientBoosting","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\n\nget_score(gbc), sorted(cross_val_score(gbc, X_train, y_train, cv=cv, scoring='f1'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\nget_score(xgb), sorted(cross_val_score(xgb, X_train, y_train, cv=cv, scoring='f1'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bagging","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'n_estimators': [1,2,5,10,20,40,100,200,500], 'max_leaf_nodes': [2,5,10,20,50,100]}\n\n#search_cv = RandomizedSearchCV(RandomForestClassifier(), param_distributions=params, \n#                               scoring='f1', n_iter=10, random_state=10)\ngrid = GridSearchCV(RandomForestClassifier(), param_grid=params, scoring='f1')\n\ngrid.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = grid.best_estimator_\nclf.fit(X_train, y_train)\nget_score(clf)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP","metadata":{}},{"cell_type":"code","source":"from sklean.nueral_network import MLP","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# End","metadata":{}},{"cell_type":"code","source":"print(round((time.time()-start),2), \"sec\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}